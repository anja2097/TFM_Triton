<p align="center">
  <img src="img/UPV.jpg" height="80">
  <img src="img/MIC.png" height="80">
</p>

# Optimizaci√≥n de redes neuronales para GPUs con Triton

**Trabajo Fin de M√°ster - M√°ster Universitario en Ingenier√≠a de Computadores y Redes - DISCA - UPV**  
**Autor**: Antonino Ciordia Barcos  
**Tutores**: Enrique S. Quintana-Ort√≠, Adri√°n Castell√≥ 




<p align="center">
  <img src="img/Triton.png" alt="Logo Triton" height="220">
</p>

---

## Resumen

Este TFM estudia el impacto del uso de [Triton](https://github.com/openai/triton), un lenguaje y compilador para kernels personalizados en GPU, en la **optimizaci√≥n de modelos de deep learning**, como:

- **Convolutional Neural Networks (CNNs)**

Se analiza el rendimiento frente a implementaciones tradicionales en PyTorch y CuPy y se exploran ventajas a nivel de coste computacional, flexibilidad y portabilidad del c√≥digo.

El objetivo principal de este Trabajo de Fin de M√°ster es el estudio, desarrollo y an√°lisis de t√©cnicas de optimizaci√≥n de redes neuronales profundas mediante el uso de [Triton](https://github.com/openai/triton), un compilador y modelo de programaci√≥n de alto nivel desarrollado por OpenAI, dise√±ado para la generaci√≥n de kernels eficientes en GPU. Debido al crecimiento del campo en los √∫ltimos a√±os y la necesidad actual de poder de c√≥mputo, esta memoria se centra en evaluar la viabilidad y eficacia del ecosistema Triton frente a entornos consolidados como CuPy o Torch.

El tipo de red sobre el que se centra este trabajo son las redes convolucionales modernas, sobre los que se aplicar√°n transoformaciones con el fin de reducirlos mayoritariamente a multiplicaciones de matrices (GEMM). Se implementar√°n versiones optimizadas de esta operaci√≥n utilizando Triton, y se comparan cuantitativamente sus resultados frente a bibliotecas convencionales, tanto en t√©rminos de rendimiento como de portabilidad y expresividad del c√≥digo.

Como modelos de referencia se emplean las arquitecturas VGG16 y ResNet-50, ampliamente utilizadas en visi√≥n por computador, sobre las cuales se realizan m√∫ltiples pruebas de rendimiento, variando par√°metros como el tipo de dato, la arquitectura hardware sobre la que se ejecuta y los niveles de autotuning disponibles. Los resultados obtenidos revelan que Triton no solo permite alcanzar desempe√±os cercanos o incluso superiores a los logrados con implementaciones altamente optimizadas en CUDA, sino que adem√°s facilita una mayor portabilidad y simplificaci√≥n en el desarrollo, al abstraer muchas de las complejidades iniciales que supone la programaci√≥n en GPU.

---

## Resultados obtenidos

<p align="center">
  <img src="img/ResNET50-FP32-B64_Optimizado.png" alt="Resultado" height="550">
</p>

---

## üìÅ Estructura del repositorio

```text
TFM_Triton/
‚îÇ
‚îú‚îÄ‚îÄ img/                          <- Im√°genes empleadas en este documento
‚îú‚îÄ‚îÄ Ejecucion_modelos.ipynb       <- Notebook principal con ejecuci√≥n de pruebas
‚îú‚îÄ‚îÄ requirements.txt              <- Librer√≠as necesarias
‚îú‚îÄ‚îÄ resultados/                   <- Directorios con resultados y salidas
‚îú‚îÄ‚îÄ LICENSE                       <- Licencia del proyecto
‚îî‚îÄ‚îÄ README.md                     <- Este documento
